data1 <- fread("wisconsin breast cancer data.csv", stringsAsFactors = T)
library(caTools)
library(data.table)
library(ggplot2)
library(neuralnet)
library(randomForest)
library(car)
library(caret)
library(e1071)
data1 <- fread("wisconsin breast cancer data.csv", stringsAsFactors = T)
summary(data1)
data1[duplicated(data1)] # check for duplication
sum(is.na(data1)) # check for any NA, although can be seen in summary(data1)
# rename concave points to concave_points for easier coding
setnames(data1, "concave points_mean", "concave_points_mean")
setnames(data1, "concave points_se", "concave_points_se")
setnames(data1, "concave points_worst", "concave_points_worst")
# change Malignant to 1, Benign to 0.
data1[,diagnosis:=ifelse(diagnosis=="M",1,0)]
data1$diagnosis<-factor(data1$diagnosis)
# remove id which is not used
data1[,id:=NULL]
summary(data1)
# Since standard error of the measurement is not the measurement of the tumour, remove standard error of all measurements.
data1[,":=" (radius_se=NULL, texture_se=NULL, perimeter_se=NULL, area_se=NULL, smoothness_se=NULL, compactness_se=NULL, concavity_se=NULL, concave_points_se=NULL, symmetry_se=NULL, fractal_dimension_se=NULL)]
table1=data.frame(matrix(NA,ncol(data1),ncol(data1)))
test <-as.data.frame.matrix(data1)
summary(test)
for (i in c(2:20)){
table1[1,i]<-colnames(data1)[i]
table1[i,1]<-colnames(data1)[i]
for (j in c(2:20)){
if (i != j){
table1[i,j]<-cor(test[,i],test[,j])
}
}
}
# correlation table 1
table1
data1[,":=" (radius_worst=NULL, texture_worst=NULL, perimeter_worst=NULL, area_worst=NULL, smoothness_worst=NULL, compactness_worst=NULL, concavity_worst=NULL, concave_points_worst=NULL)]
table2=data.frame(matrix(NA,ncol(data1),ncol(data1)))
test <-as.data.frame.matrix(data1)
summary(test)
for (i in c(2:ncol(data1))){
table2[1,i]<-colnames(data1)[i]
table2[i,1]<-colnames(data1)[i]
for (j in c(2:ncol(data1))){
if (i != j){
table2[i,j]<-cor(test[,i],test[,j])
}
}
}
# second cor table
table2
data1[,":=" (radius_mean=NULL, perimeter_mean=NULL, compactness_mean=NULL, concave_points_mean=NULL)]
table3=data.frame(matrix(NA,ncol(data1),ncol(data1)))
test <-as.data.frame.matrix(data1)
summary(test)
for (i in c(2:ncol(data1))){
table3[1,i]<-colnames(data1)[i]
table3[i,1]<-colnames(data1)[i]
for (j in c(2:ncol(data1))){
if (i != j){
table3[i,j]<-cor(test[,i],test[,j])
}
}
}
# 3rd cor table for final check
table3
summary(data1)
# calculating VIF
test.mod<-glm(diagnosis~.,family=binomial, data=data1)
vif(test.mod)
# Since our sample size is rather small, we will use a stricter VIF threshold of 5, and will remove fractal_dimension_mean
data1[, fractal_dimension_mean:=NULL]
test.mod2<-glm(diagnosis~.,family=binomial, data=data1)
vif(test.mod2)
test<-data1
# Exploratory data analysis
ggplot(test)+aes(y=texture_mean)+geom_boxplot()
ggplot(test)+aes(y=area_mean)+geom_boxplot()
ggplot(test)+aes(y=smoothness_mean)+geom_boxplot()
ggplot(test)+aes(y=concavity_mean)+geom_boxplot()
ggplot(test)+aes(y=symmetry_mean)+geom_boxplot()
ggplot(test)+aes(y=symmetry_worst)+geom_boxplot()
ggplot(test)+aes(y=fractal_dimension_worst)+geom_boxplot()
# seem to have many positively-skewed data (right-tailed), thus, test for skewness
#skewness
skewness(data1$texture_mean)
skewness(data1$area_mean)
skewness(data1$smoothness_mean)
skewness(data1$concavity_mean)
skewness(data1$symmetry_mean)
skewness(data1$symmetry_worst)
skewness(data1$fractal_dimension_worst)
# since most data is right-tailed, will do log transformation for skewness>1 (area_mean, concavity_mean, symmetry_worst, fractal_dimension_worst), but since the concavity_mean, symmetry_mean and fractal_dimension_worst is below 1 and concavity_mean has 0 value within data, will use log(x+1) instead of just log(x).
data1$area_mean<-log(data1$area_mean+1)
data1$concavity_mean<-log(data1$concavity_mean+1)
data1$symmetry_worst<-log(data1$symmetry_worst+1)
data1$fractal_dimension_worst<-log(data1$fractal_dimension_worst+1)
# normalize data with min=0, max=1 (feature scaling)
process<-preProcess(data1,method=c("range"))
norm_scale<-predict(process,data1)
data1<-norm_scale
data1
ggplot(data1)+aes(y=texture_mean)+geom_boxplot()
ggplot(data1)+aes(y=area_mean)+geom_boxplot()
ggplot(data1)+aes(y=smoothness_mean)+geom_boxplot()
ggplot(data1)+aes(y=concavity_mean)+geom_boxplot()
ggplot(data1)+aes(y=symmetry_mean)+geom_boxplot()
ggplot(data1)+aes(y=symmetry_worst)+geom_boxplot()
ggplot(data1)+aes(y=fractal_dimension_worst)+geom_boxplot()
test<-data1
#remove outliers
outlier.value<-1.5*(summary(test$texture_mean)[5]-summary(test$texture_mean)[2])
data1 <-data1[texture_mean<=outlier.value+summary(test$texture_mean)[5] & texture_mean >=summary(test$texture_mean)[2]-outlier.value | is.na(texture_mean)]
outlier.value<-1.5*(summary(test$area_mean)[5]-summary(test$area_mean)[2])
data1 <-data1[area_mean<=outlier.value+summary(test$area_mean)[5] & area_mean >=summary(test$area_mean)[2]-outlier.value | is.na(area_mean)]
outlier.value<-1.5*(summary(test$smoothness_mean)[5]-summary(test$smoothness_mean)[2])
data1 <-data1[smoothness_mean<=outlier.value+summary(test$smoothness_mean)[5] & smoothness_mean >=summary(test$smoothness_mean)[2]-outlier.value | is.na(smoothness_mean)]
outlier.value<-1.5*(summary(test$concavity_mean)[5]-summary(test$concavity_mean)[2])
data1 <-data1[concavity_mean<=outlier.value+summary(test$concavity_mean)[5] & concavity_mean >=summary(test$concavity_mean)[2]-outlier.value | is.na(concavity_mean)]
outlier.value<-1.5*(summary(test$symmetry_mean)[5]-summary(test$symmetry_mean)[2])
data1 <-data1[symmetry_mean<=outlier.value+summary(test$symmetry_mean)[5] & symmetry_mean >=summary(test$symmetry_mean)[2]-outlier.value | is.na(symmetry_mean)]
outlier.value<-1.5*(summary(test$symmetry_worst)[5]-summary(test$symmetry_worst)[2])
data1 <-data1[symmetry_worst<=outlier.value+summary(test$symmetry_worst)[5] & symmetry_worst >=summary(test$symmetry_worst)[2]-outlier.value | is.na(symmetry_worst)]
outlier.value<-1.5*(summary(test$fractal_dimension_worst)[5]-summary(test$fractal_dimension_worst)[2])
data1 <-data1[fractal_dimension_worst<=outlier.value+summary(test$fractal_dimension_worst)[5] & fractal_dimension_worst >=summary(test$fractal_dimension_worst)[2]-outlier.value | is.na(fractal_dimension_worst)]
summary(data1)
sum(data1$diagnosis==1)/nrow(data1)
# train test split
set.seed(234)
train1<-sample.split(Y=data1$diagnosis,SplitRatio = 0.7)
trainset<-subset(data1,train1==T)
testset<-subset(data1,train1==F)
trainset
testset
# Random Forest
ncol(data1) # 8 but -1 for diagnosis so 7
floor(log(7,2)+1) # 3 for mtry
# calibrating for optimal number of trees with OOB error
B=c(100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000)
OOB.error<-seq(1:length(B))
for (i in 1:length(B)){
set.seed(234)
m.RF<- randomForest(diagnosis ~ . , data = trainset,mtry=3,ntree=B[i])
OOB.error[i]<-m.RF$err.rate[m.RF$ntree,1]
}
OOB.error
results<- data.frame(B, OOB.error)
results
# lowest OOB error appears at 150, but starts stabilizing at lowest point from 350. Thus, will use 350
set.seed(234)
m.RF.1 <- randomForest(diagnosis ~ . , data = trainset, mtry=3,ntree=350, importance = T)
m.RF.1
# trainset model and confusion matrix
rf.acc=mean(testset$diagnosis==predict(m.RF.1, newdata = testset)) # Accuracy
rf.cm<-table("testset"=testset$diagnosis,"Random Forest"=predict(m.RF.1, newdata = testset)) # testset confusion matrix
rf.fp<-rf.cm[1,2]/(rf.cm[1,2]+rf.cm[1,1]) # False Positive
rf.fn<-rf.cm[2,1]/(rf.cm[2,1]+rf.cm[2,2]) # False Negative
rf.precision<-rf.cm[2,2]/(rf.cm[1,2]+rf.cm[2,2]) # Precision
rf.recall<-rf.cm[2,2]/(rf.cm[2,1]+rf.cm[2,2]) # Recall
# 10-fold cv logistic regression
cv<- trainControl(method = "cv", number=10)
set.seed(234)
glm1 <- train(diagnosis~., data=trainset, method="glm", trControl=cv)
summary(glm1)
# symmetry_mean and fractal_dimension_worst more than p-value of 0.05. Thus, not included in the next model
set.seed(234)
glm2<-train(diagnosis~.-symmetry_mean-fractal_dimension_worst, data=trainset, method="glm", trControl=cv)
summary(glm2)
table("trainset"=trainset$diagnosis,"Logistic Regression"=predict(glm2))
# trainset confusion matrix
glm.acc<-mean(testset$diagnosis==predict(glm2, newdata = testset)) # accuracy
glm.cm<-table("testset"=testset$diagnosis, "Logistic Regression"=predict(glm2, newdata = testset))# testset confusion matrix
glm.fp<-glm.cm[1,2]/(glm.cm[1,2]+glm.cm[1,1]) # False Positive
glm.fn<-glm.cm[2,1]/(glm.cm[2,1]+glm.cm[2,2]) # False Negative
glm.precision<-glm.cm[2,2]/(glm.cm[1,2]+glm.cm[2,2]) # Precision
glm.recall<-glm.cm[2,2]/(glm.cm[2,1]+glm.cm[2,2]) # Recall
# Neural Network
hidden.list <- list(2,3,4,5,c(2,2),c(2,3),c(2,4),c(2,5),c(3,2), c(3,3),c(3,4),c(3,5),c(4,2),c(4,3),c(4,4),c(4,5),c(5,2),c(5,3),c(5,4),c(5,5)) # calibrate for 1 or 2 hidden layer for 2,3,4, or 5 nodes in each hidden layer
nn.test<-data.frame(matrix(NA,length(hidden.list),6))
colnames(nn.test) = c("number","Accuracy","False Positive", "False Negative", "Precision", "Recall")
for (i in 1:length(hidden.list)){
nn.test[i,1]<-i
set.seed(234)
m1<-NA
m1 <- neuralnet(diagnosis~., data=trainset, hidden=unlist(hidden.list[i]), err.fct="ce", linear.output=FALSE, algorithm="rprop+")
if (is.null(m1$net.result)==FALSE){# in cases where algorithm does not converge
out <- as.data.frame(m1$net.result)
pred.m1 <- ifelse(unlist(out[,2]) > 0.5, 1, 0)
table(trainset$diagnosis, pred.m1)
test.pred <- ifelse(predict(m1,newdata=testset)[,2]>0.5,1,0)
nn.cm<-table(testset$diagnosis,test.pred)
nn.test[i,2]<-mean(test.pred == testset$diagnosis)
nn.test[i,3]<-nn.cm[1,2]/(nn.cm[1,2]+nn.cm[1,1]) # False Positive
nn.test[i,4]<-nn.cm[2,1]/(nn.cm[2,1]+nn.cm[2,2]) # False Negative
nn.test[i,5]<-nn.cm[2,2]/(nn.cm[1,2]+nn.cm[2,2]) # Precision
nn.test[i,6]<-nn.cm[2,2]/(nn.cm[2,1]+nn.cm[2,2]) # Recall
}
}
